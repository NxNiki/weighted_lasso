---
title: "weighted_lasso_simulation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## regression with informative and noise predictors
```{r}
rm(list = ls())

library(glmnet)
library(reshape2)

source("functions_reproducibility_index.R")
# define informative predictors and noise predictors
num.info.predictors = 20
num.samples = 5000

#num.noise.predictors.list = 2^seq(5, 6, by = 1)
num.noise.predictors.list = 100
#num.samples.list = seq(100, 1000, by = 100) 

x.sd = 10

dir.name = paste("wlasso_cutoff_info_predictors", toString(num.info.predictors), "samples", toString(num.samples))

if (!file.exists(dir.name)){
    dir.create(dir.name)
}

len.list = length(num.noise.predictors.list)
#print(lambda.seq)

set.seed(111)
xinfo.err = runif(num.info.predictors,0.5,1)

coef.true = vector("list", length = len.list)

penalty.weight.result = list()

for (i.list in 1:len.list) {
    
    num.noise.predictors = num.noise.predictors.list[i.list]
    num.predictors = num.info.predictors + num.noise.predictors
    
    print("number of info predictors and noise predictors:")
    print(num.info.predictors)
    print(num.noise.predictors)

    set.seed(123)
    beta = c(runif(num.info.predictors, min = 0.2, max = 2)*sample(c(-1,1), num.info.predictors, replace = T),
             rep(0, 1, num.noise.predictors))
    
    sim.data = simulate_data(num.samples, beta, x.sd, seed = 111)
    x = sim.data$X
    y = sim.data$y
    
    x.scale = scale.0.1(x)
    
    set.seed(444)
    print('computing feature weights mean difference boot...')
    penalty.weight.mean.diff.boot = feature.weight.mean.diff.boot(x.scale, y, nboots = 500, cutoff = c(0.1, .9), log.base = 100)
    print('computing feature weights ttest...')
    penalty.weight.ttest = feature.weight.test(x.scale, y, method = "ttest", cutoff = c(0.1, .9), log.base = 100)
    print('computing feature weights kfold')
    penalty.weight.kfold = feature.weight.mean.diff.kfold(x.scale, y, k = 10, cutoff = c(0.1, .9), log.base = 100)
    print('computing feature weights sd + mean difference boot...')
    penalty.weight.sd.mean.diff.boot = feature.weight.sd.mean.diff.boot(x.scale, y, nboots = 500, cutoff = c(0.1, .9), log.base = 100)
    
    penalty.weight.result[[i.list]] = cbind(penalty.weight.mean.diff.boot, 
                                            penalty.weight.ttest, 
                                            penalty.weight.kfold, 
                                            penalty.weight.sd.mean.diff.boot)
    
    print('feature weights finished!')

}
```
# plot feature weights:
```{r, fig1, fig.width = 9, fig.height= 3.5}
method.name = c("mean difference boot", "ttest", "kfold", "sd mean difference boot")
method.select = c("mean difference boot", "ttest", "kfold")

for (i.list in 1:len.list){
    
    plot.df = as.data.frame(penalty.weight.result[[i.list]])
    colnames(plot.df) = method.name
    plot.df = plot.df[, method.select]
    plot.df$beta = beta
    #plot.df = data.frame(beta = beta, ttest = penalty.weight.t)
    
    plot.df = melt(plot.df, id.var = c("beta"), variable.name = "method")
    plot.df$feature.type = plot.df$beta!=0
    print(plot.df)
    
    p = ggplot(plot.df, aes(x = beta, y = value, group = feature.type, color = feature.type)) +
        facet_wrap(~method, scales = "free") +
        geom_point(alpha = .5)
        #annotate(geom="text", x=-4.5, y=.80, 
        #         label=c(paste("noise predictors:", toString(num.noise.predictors), sep = ''), '', '', ''), color="black", hjust = 0) +
        #annotate(geom="text", x=-4.5, y=.88, 
        #         label=c(paste("true predictors:", toString(num.info.predictors), sep = ''), '', '', ''), color="black", hjust = 0)

    #ggMarginal(p, groupColour = TRUE, groupFill = TRUE, margins = "y")
    print(p)
    
    p = ggplot(plot.df, aes(x = value, fill = feature.type, color = feature.type)) +
        facet_wrap(~method, scales = "free") +
        geom_density(alpha = .5)
        #annotate(geom="text", x=-3.5, y=.80, 
        #         label=c(paste("noise predictors:", toString(num.noise.predictors), sep = ''), '', '', ''),
        #         color="black", hjust = 0) +
        #annotate(geom="text", x=-3.5, y=.86, 
        #         label=c(paste("true predictors:", toString(num.info.predictors), sep = ''), '', '', ''),
        #         color="black", hjust = 0)
    print(p)
    
    

#coef.w.lasso[[i.list]] = w.lasso.coefs
}

```

```{r}
library(ggplot2)
library(ggExtra)

# basic usage
#p <- ggplot(mtcars, aes(wt, mpg)) + geom_point()
#ggMarginal(p)

# using some parameters
p <- ggplot(mtcars, aes(x = wt, y = drat, colour = factor(vs))) +
     geom_point()
#ggMarginal(p, groupColour = TRUE)
ggMarginal(p, groupColour = TRUE, groupFill = TRUE, margins = "y",)
print(p)
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
